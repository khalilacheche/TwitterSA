# Machine Learning Project 2 - Tweets Sentiment Analysis üê¶


## Team Members

- Khalil Acheche: khalil.acheche@epfl.ch

- Mehdi Mezghani: mehdi.mezghani@epfl.ch

- Youssef Mamlouk: youssef.mamlouk@epfl.ch

## Goal of the Project :

The goal of this project is to determine whether a tweet used to contain a positive ( üôÇ ) or negative ( üôÅ ) emoji.
We will be using a dataset containing 2.5M tweets, 50% of them are positive, the other half is negative.

We used different different ML techniques for NLP to achieve this result, which are discussed more in detail in the pdf report.

A fine-tuned model based on BERT allowed us to reach an accuracy of 91.4% on [aicrowd](https://www.aicrowd.com/challenges/epfl-ml-text-classification)


## Files
- `data_cleaning.ipynb` : A jupyter notebook with the data preprocessing pipeline that we used to prepare the tweets for the model
- `deep_learning_modules.py` : the module containing the deep learning models
- `deep_learning_train.ipynb` : A jupyter notebook to train the deep learning models
- `run.ipynb` : A jupyter notebook to make predictions on the test set for ai_crowd based on a locally saved model
- `TF_IDF-N_grams.ipynb` : An implementation of a model based on logistic regression with TF_IDF  embedding
- `Word2Vec-NN.ipynb`: An implementation of an MLP with Word2Vec embedding
- `report.pdf`: The paper providing a detailed description of the different approaches that we took to tackle this problem.
- `README.md` : this README file

## Reproducibility


### 1- Requirements:

In order to run the project, you need the following librairies installed:

- `torch`
- `transformers`
- `nltk`
- `pandas`
- `pickle`
- `sklearn`
- `tqdm`
- `re`
- `pandas`
- `numpy`
- `matplotlib`
- `ekphrasis`
- `seaborn`

### 2- Steps:

To reproduce our best result:
1. download [this](https://drive.google.com/file/d/168OcXuTSPEoiBhpJdQMhRNqjLEsTXHkZ/view?usp=sharing) compressed archive, containing our dataset as well as the trained model that got us the best submission

2. unzip the file and place the two folders (`models` and `data`) inside the directory of the project

3. (optional) if you want to retrain the models, you can run the `deep_learning_train.ipynb` jupyter notebook. This will create a file inside the models directory, for each epoch of the training process

4. run the `run.ipynb` notebook to generate a CSV file that can be submitted in the aicrowd competition (you can choose different models by specifying the path and model parameters)

Notes:
- The models and data are provided separately because they are too large to be hosted on github
- In the `models` folder, we provided the models that allowed us to achieve the two best results on different architectures
- The `run.ipynb` and `deep_learning_train.ipynb` use the preprocessed tweets that were generated by the `data_cleaning.ipynb` notebook. They are provided in the data folder named `train_cleaned.txt` and `test_cleaned.txt`
